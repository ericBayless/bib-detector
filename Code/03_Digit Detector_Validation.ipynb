{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "distinguished-teacher",
   "metadata": {},
   "source": [
    "# 03. Preprocessing Street View Housing Numbers (SVHN) Dataset\n",
    "\n",
    "### Purpose:\n",
    "Using the provided RBNR annotations, crop out the defined bibs and feed each bib into the digit detector.  During the cropping process, a text file containing the image names of the cropped bib files along their true RBN will be created.  A similar list will also be created for the predicted RBNs during the digit detection step.  These lists can then be compared in the validation section.\n",
    "\n",
    "Set1 and Set2 of the RBNR dataset will be used later to train the bib detection model, but neither set has been used in training the digit detection model.  Therefore all three sets are being used as validation for this step.\n",
    "\n",
    "### Before Running Notebook:\n",
    "1. Create a folder named Validation under the top level of this repo.\n",
    "1. Create a folder named Bibs under ./Data/Validation/.  This is where the croped bib images will be saved along with the list of image names and bib numbers in a text file for validation.\n",
    "1. Download the config file and weights file from Google Drive for the digit detection model.  These were created in the previous notebook (02_SVHN_YOLOv4_tiny_Darknet_Roboflow.ipynb).  Save them in ./Data/YOLO/num_reader/ from the top level of this repo, and make sure they are set as the value of configPath and weightsPath in the Digit Detection section. \n",
    "1. Create a folder named Nums under ./Data/Validation/.  This is where the annotated images along with the text file containing the predicted bib numbers will be saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "jewish-devices",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "convertible-evidence",
   "metadata": {},
   "source": [
    "# Crop Bibs\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "voluntary-shuttle",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cropped_bib(image, input_path, out_path):  \n",
    "    \"\"\"\n",
    "    Read in the RBNR image bounding box information and use it to save\n",
    "    cropped out images of the bibs in the original image.  Then write\n",
    "    the cropped bib image name and RBN to file.\n",
    "    \n",
    "    Args\n",
    "        image (str): name of original image\n",
    "        input_path (str): path to directory of image\n",
    "        out_path (str): directory where results are saved\n",
    "        \n",
    "    Returns\n",
    "        None\n",
    "    \"\"\"\n",
    "    \n",
    "    #load image\n",
    "    img = cv.imread(input_path + image)\n",
    "    \n",
    "    # load annotation file\n",
    "    f = sio.loadmat(input_path + image + '.mat')\n",
    "\n",
    "    #get bounding boxes and bib numbers\n",
    "    boxes = f['tagp']\n",
    "    numbers = f['number'].flatten()\n",
    "\n",
    "    for i, box in enumerate(boxes):\n",
    "        #convert box values to int\n",
    "        (t, b, l, r) = [int(i) for i in box]\n",
    "        # crop image and save\n",
    "        crop_img = img[t:b, l:r]\n",
    "        crop_name = image[:-4]+'_'+'bib_'+str(i+1)+'.JPG'\n",
    "        cv.imwrite(out_path + crop_name, crop_img)\n",
    "        # write race bib number to file\n",
    "        rbn_file = open(output_path + 'bib_numbers.txt', 'a')\n",
    "        rbn_file.writelines(f\"{crop_name},{numbers[i]}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "extra-tractor",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set input and output info for set1\n",
    "images_path = '../Data/RBNR/set1_org/'\n",
    "images = [file for file in os.listdir(images_path) if file[-3:]=='JPG']\n",
    "\n",
    "output_path = '../Data/Validation/Bibs/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "effective-corps",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check for existing bib_numbers.txt and remove if exists\n",
    "if os.path.exists(output_path + 'bib_numbers.txt'):\n",
    "    os.remove(output_path + 'bib_numbers.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "square-correction",
   "metadata": {},
   "outputs": [],
   "source": [
    "for image in images:\n",
    "    get_cropped_bib(image, images_path, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "arranged-membership",
   "metadata": {},
   "outputs": [],
   "source": [
    "# repeat process for set2\n",
    "images_path = '../Data/RBNR/set2_org/'\n",
    "images = [file for file in os.listdir(images_path) if file[-3:]=='JPG']\n",
    "\n",
    "for image in images:\n",
    "    get_cropped_bib(image, images_path, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ultimate-border",
   "metadata": {},
   "outputs": [],
   "source": [
    "# repeat process for set3\n",
    "images_path = '../Data/RBNR/set3_org/'\n",
    "images = [file for file in os.listdir(images_path) if file[-3:]=='JPG']\n",
    "\n",
    "for image in images:\n",
    "    get_cropped_bib(image, images_path, output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chubby-sudan",
   "metadata": {},
   "source": [
    "# Digit Detection\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dried-capitol",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get random colors for boxes\n",
    "np.random.seed(42)\n",
    "colors = np.random.randint(0, 255, size=(10, 3), dtype='uint8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cooperative-trading",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Give the configuration and weight files for the model and load the network.\n",
    "configPath = '../Data/YOLO/num_reader/SVHN3_custom-yolov4-tiny-detector.cfg'\n",
    "weightsPath = '../Data/Yolo/num_reader/SVHN3_custom-yolov4-tiny-detector_best.weights'\n",
    "\n",
    "net = cv.dnn.readNetFromDarknet(configPath, weightsPath)\n",
    "net.setPreferableBackend(cv.dnn.DNN_BACKEND_OPENCV)\n",
    "\n",
    "# determine the output layer\n",
    "ln = net.getLayerNames()\n",
    "ln = [ln[i[0] - 1] for i in net.getUnconnectedOutLayers()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "found-growth",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_labeled_image(image, input_path, out_path): \n",
    "    \"\"\"\n",
    "    Run digit detection and save a labeled image.  Then compile digits\n",
    "    into single RBN and save to file for validation.\n",
    "    Code for using YOLO in OpenCV adapted from OpenCV Docs:\n",
    "    https://opencv-tutorial.readthedocs.io/en/latest/yolo/yolo.html\n",
    "    \n",
    "    Args\n",
    "        image (str): name of original image\n",
    "        input_path (str): path to directory of image\n",
    "        out_path (str): directory where results are saved\n",
    "        \n",
    "    Returns\n",
    "        None\n",
    "    \"\"\"\n",
    "    # read in image and construct a blob from the image\n",
    "    img = cv.imread(input_path + image)\n",
    "    blob = cv.dnn.blobFromImage(img, 1/255.0, (416, 416), swapRB=True, crop=False)\n",
    "\n",
    "    # get detections\n",
    "    net.setInput(blob)\n",
    "    outputs = net.forward(ln)\n",
    "\n",
    "    # initialize lists\n",
    "    boxes = []\n",
    "    confidences = []\n",
    "    classIDs = []\n",
    "    \n",
    "    # initialize image dimensions\n",
    "    h_img, w_img = img.shape[:2]\n",
    "\n",
    "    for output in outputs:\n",
    "        for detection in output:\n",
    "            scores = detection[5:]\n",
    "            classID = np.argmax(scores)\n",
    "            confidence = scores[classID]\n",
    "\n",
    "            # Only keep detection if it is for a digit with high confidence\n",
    "            if confidence > 0.5:\n",
    "                box = detection[:4] * np.array([w_img, h_img, w_img, h_img])\n",
    "                (centerX, centerY, width, height) = box.astype(\"int\")\n",
    "                x = int(centerX - (width / 2))\n",
    "                y = int(centerY - (height / 2))\n",
    "                box = [x, y, int(width), int(height)]\n",
    "                boxes.append(box)\n",
    "                confidences.append(float(confidence))\n",
    "                classIDs.append(classID)\n",
    "                \n",
    "    # get indices of final bounding boxes  \n",
    "    indices = cv.dnn.NMSBoxes(boxes, confidences, 0.5, 0.4)\n",
    "    # initialize list for digit position and value\n",
    "    bib_digit_loc = []\n",
    "    if len(indices) > 0:\n",
    "        for i in indices.flatten():\n",
    "            (x, y) = (boxes[i][0], boxes[i][1])\n",
    "            (w, h) = (boxes[i][2], boxes[i][3])\n",
    "            color = [int(c) for c in colors[classIDs[i]]]\n",
    "            \n",
    "            cv.rectangle(img, (x, y), (x + w, y + h), color, 1)\n",
    "            text = \"{}: {:.4f}\".format(classIDs[i], confidences[i])\n",
    "            cv.putText(img, text, (x, y - 5), cv.FONT_HERSHEY_SIMPLEX, 0.5, color, 1)\n",
    "            \n",
    "            bib_digit_loc.append((x, str(classIDs[i])))\n",
    "        \n",
    "        # save annotated image\n",
    "        cv.imwrite(out_path+image[:-4]+'_'+'detected'+'.JPG', img)\n",
    "        \n",
    "        # write race bib number to file\n",
    "        bib_digit_loc.sort()\n",
    "        rbn_pred = int(''.join([i[1] for i in bib_digit_loc]))\n",
    "        #orig_image = '_'.join(image.split('_')[:2]) + '.JPG'\n",
    "        rbn_pred_file = open(out_path + 'rbn_preds.txt', 'a')\n",
    "        rbn_pred_file.writelines(f\"{image},{rbn_pred}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "jewish-concentration",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set input and output info for detections\n",
    "images_path = '../Data/Validation/Bibs/'\n",
    "images = [file for file in os.listdir(images_path) if file[-3:]=='JPG']\n",
    "\n",
    "output_path = '../Data/Validation/Nums/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "artistic-certificate",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check for existing bib_numbers.txt and remove if exists\n",
    "if os.path.exists(output_path + 'rbn_preds.txt'):\n",
    "    os.remove(output_path + 'rbn_preds.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "collective-subdivision",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run detections on all images in input directory\n",
    "for image in images:\n",
    "    create_labeled_image(image, images_path, output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "extensive-clock",
   "metadata": {},
   "source": [
    "# Validation\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "grand-picking",
   "metadata": {},
   "source": [
    "## Training Validation\n",
    "![Digit Detection](../Presentation/Images/SVHN_training_validation.png \"Digit Detection\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "metropolitan-pixel",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rbn</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>image</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>set1_62_bib_1.JPG</th>\n",
       "      <td>941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>set1_76_bib_1.JPG</th>\n",
       "      <td>3621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>set1_89_bib_1.JPG</th>\n",
       "      <td>1703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>set1_88_bib_1.JPG</th>\n",
       "      <td>1442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>set1_77_bib_1.JPG</th>\n",
       "      <td>847</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    rbn\n",
       "image                  \n",
       "set1_62_bib_1.JPG   941\n",
       "set1_76_bib_1.JPG  3621\n",
       "set1_89_bib_1.JPG  1703\n",
       "set1_88_bib_1.JPG  1442\n",
       "set1_77_bib_1.JPG   847"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_df = pd.read_csv('../Data/Validation/Bibs/bib_numbers.txt', delimiter=',', \n",
    "                      index_col=0, names=['image', 'rbn'])\n",
    "true_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "forced-democracy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 290 entries, set1_62_bib_1.JPG to set3_42_bib_1.JPG\n",
      "Data columns (total 1 columns):\n",
      " #   Column  Non-Null Count  Dtype\n",
      "---  ------  --------------  -----\n",
      " 0   rbn     290 non-null    int64\n",
      "dtypes: int64(1)\n",
      "memory usage: 4.5+ KB\n"
     ]
    }
   ],
   "source": [
    "true_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "boring-award",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred_rbn</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>image</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>set3_21_bib_2.JPG</th>\n",
       "      <td>3054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>set1_29_bib_1.JPG</th>\n",
       "      <td>130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>set2_27_bib_2.JPG</th>\n",
       "      <td>20927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>set2_50_bib_1.JPG</th>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>set3_56_bib_1.JPG</th>\n",
       "      <td>2244</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   pred_rbn\n",
       "image                      \n",
       "set3_21_bib_2.JPG      3054\n",
       "set1_29_bib_1.JPG       130\n",
       "set2_27_bib_2.JPG     20927\n",
       "set2_50_bib_1.JPG        89\n",
       "set3_56_bib_1.JPG      2244"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df = pd.read_csv('../Data/Validation/Nums/rbn_preds.txt', delimiter=',', \n",
    "                      index_col=0, names=['image', 'pred_rbn'])\n",
    "pred_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "intended-convertible",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 286 entries, set3_21_bib_2.JPG to set3_03_bib_6.JPG\n",
      "Data columns (total 1 columns):\n",
      " #   Column    Non-Null Count  Dtype\n",
      "---  ------    --------------  -----\n",
      " 0   pred_rbn  286 non-null    int64\n",
      "dtypes: int64(1)\n",
      "memory usage: 4.5+ KB\n"
     ]
    }
   ],
   "source": [
    "pred_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "polish-calibration",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df = pd.merge(true_df, pred_df, on='image', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "complete-clinton",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 290 entries, set1_62_bib_1.JPG to set3_42_bib_1.JPG\n",
      "Data columns (total 2 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   rbn       290 non-null    int64  \n",
      " 1   pred_rbn  286 non-null    float64\n",
      "dtypes: float64(1), int64(1)\n",
      "memory usage: 6.8+ KB\n"
     ]
    }
   ],
   "source": [
    "all_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "horizontal-agriculture",
   "metadata": {},
   "source": [
    "#### Accurate Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "assigned-islam",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rbn</th>\n",
       "      <th>pred_rbn</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>image</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>set1_76_bib_1.JPG</th>\n",
       "      <td>3621</td>\n",
       "      <td>3621.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>set1_75_bib_1.JPG</th>\n",
       "      <td>1676</td>\n",
       "      <td>1676.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>set1_61_bib_1.JPG</th>\n",
       "      <td>1679</td>\n",
       "      <td>1679.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>set1_48_bib_1.JPG</th>\n",
       "      <td>663</td>\n",
       "      <td>663.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>set1_60_bib_1.JPG</th>\n",
       "      <td>1404</td>\n",
       "      <td>1404.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>set3_55_bib_2.JPG</th>\n",
       "      <td>4624</td>\n",
       "      <td>4624.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>set3_43_bib_1.JPG</th>\n",
       "      <td>2074</td>\n",
       "      <td>2074.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>set3_57_bib_2.JPG</th>\n",
       "      <td>4183</td>\n",
       "      <td>4183.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>set3_56_bib_1.JPG</th>\n",
       "      <td>2244</td>\n",
       "      <td>2244.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>set3_42_bib_1.JPG</th>\n",
       "      <td>3554</td>\n",
       "      <td>3554.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>196 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    rbn  pred_rbn\n",
       "image                            \n",
       "set1_76_bib_1.JPG  3621    3621.0\n",
       "set1_75_bib_1.JPG  1676    1676.0\n",
       "set1_61_bib_1.JPG  1679    1679.0\n",
       "set1_48_bib_1.JPG   663     663.0\n",
       "set1_60_bib_1.JPG  1404    1404.0\n",
       "...                 ...       ...\n",
       "set3_55_bib_2.JPG  4624    4624.0\n",
       "set3_43_bib_1.JPG  2074    2074.0\n",
       "set3_57_bib_2.JPG  4183    4183.0\n",
       "set3_56_bib_1.JPG  2244    2244.0\n",
       "set3_42_bib_1.JPG  3554    3554.0\n",
       "\n",
       "[196 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_df.loc[all_df['rbn'] == all_df['pred_rbn']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "opened-serbia",
   "metadata": {},
   "source": [
    "#### No Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "changed-education",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rbn</th>\n",
       "      <th>pred_rbn</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>image</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>set1_28_bib_1.JPG</th>\n",
       "      <td>311</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>set1_16_bib_1.JPG</th>\n",
       "      <td>1463</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>set1_17_bib_1.JPG</th>\n",
       "      <td>1463</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>set1_07_bib_1.JPG</th>\n",
       "      <td>979</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    rbn  pred_rbn\n",
       "image                            \n",
       "set1_28_bib_1.JPG   311       NaN\n",
       "set1_16_bib_1.JPG  1463       NaN\n",
       "set1_17_bib_1.JPG  1463       NaN\n",
       "set1_07_bib_1.JPG   979       NaN"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_df.loc[all_df['pred_rbn'].isna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worthy-static",
   "metadata": {},
   "source": [
    "#### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "macro-annex",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6758620689655173"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_positives = len(all_df.loc[all_df['rbn'] == all_df['pred_rbn']])\n",
    "total = len(true_df)\n",
    "\n",
    "true_positives / total"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adolescent-southwest",
   "metadata": {},
   "source": [
    "# Conclusions\n",
    "---\n",
    "\n",
    "The overall accuracy of the digit detector when putting together RBN's could be higher; however, when looking at the inaccurate predictions, many are only off by a single digit.  Given that this model will be used in real time where an athlete can be moved to aquire the best possible read, it is most likely sufficient.  Also it has been shown by previous researchers that using the SVHN dataset in combination with a large set of racing bib number images for training produces a better result.  Further information on that study can be found [here](https://www.researchgate.net/publication/335234017_Racing_Bib_Number_Recognition_Using_Deep_Learning).  Future work will enclude gathering images more specifically related to the end goal of identifying a single bib number after the conclusion of the race, and retraining the model with that set included."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intensive-sheffield",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
